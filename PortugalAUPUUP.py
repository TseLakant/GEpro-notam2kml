import os
from lxml import etree
from bs4 import BeautifulSoup
import re
import io
from playwright.sync_api import sync_playwright
import time


# --- –ü–ê–†–ê–ú–ï–¢–†–´ ---
HTML_FILE = "AUP_UUP Details.htm"
INPUT_KML = "Data Base.kml"
OUTPUT_KML = "Active Regions.kml"
KML_NS = 'http://www.opengis.net/kml/2.2' # –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∏–º–µ–Ω –¥–ª—è GEpro KML 2.2
FULL_COPY = ["SUPLEMENTOS ACTIVIDADES", "ESPA√áO A√âREO", "AERODROMOS E CAMPOS VOO"]  # –≠—Ç–∏ –ø–∞–ø–∫–∏ –ø–æ–ª–µ—Ç—è—Ç –≤ —Ñ–∞–π–ª —Ü–µ–ª–∏–∫–æ–º


def download_page():
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)
        context = browser.new_context()
        page = context.new_page()

        page.goto('https://www.public.nm.eurocontrol.int/PUBPORTAL/gateway/spec/')

        # –ü–µ—Ä–µ–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—Ä–µ–º–µ–Ω–∏, —á—Ç–æ –±—ã –ø–µ—Ä–µ–π—Ç–∏ –ø–æ —Å—Å—ã–ª–∫–µ, (–∫–∞–∂–¥–∞—è –ø–æ–ø—ã—Ç–∫–∞ +- 2 —Å–µ–∫)
        cur_time = time.localtime()
        cur_date = '/'.join([str(cur_time.tm_mday + 100)[1:3], str(cur_time.tm_mon + 100)[1:3], str(cur_time.tm_year)])
        cur_hour = cur_time.tm_hour - 5
        for trying_time in range(cur_hour * 2 + 2):
            cur_time = ':'.join([str(cur_hour - trying_time // 2 + 100)[1:3], ['30', '00'][trying_time % 2]])
            need_page = cur_date + " " + cur_time
            try:
                # –û–∂–∏–¥–∞–µ–º –ø–æ—è–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–π –≤–∫–ª–∞–¥–∫–∏ (page) –ø–æ—Å–ª–µ –∫–ª–∏–∫–∞
                with context.expect_page() as new_page_info:
                    # –ö–ª–∏–∫–∞–µ–º –ø–æ —Å—Å—ã–ª–∫–µ/–∫–Ω–æ–ø–∫–µ
                    page.get_by_text(need_page).click(timeout=2000)
                    break
            except Exception as e:
                print(f'failed to get page: {need_page}')

            # –≠—Ç–æ –∏ –µ—Å—Ç—å —Ç–∞ —Å–∞–º–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞, –∫–æ—Ç–æ—Ä–∞—è –æ—Ç–∫—Ä—ã–ª–∞—Å—å
        target_page = new_page_info.value

        # –ñ–¥–µ–º, –ø–æ–∫–∞ JS –æ—Ç—Ä–∏—Å—É–µ—Ç —Ç–∞–±–ª–∏—Ü—É (networkidle ‚Äî –Ω–µ—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Ç–µ—á–µ–Ω–∏–µ 0.5 —Å–µ–∫)
        target_page.wait_for_load_state("networkidle")

        # –ü–æ–ª—É—á–∞–µ–º —á–∏—Å—Ç—ã–π HTML –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
        html_code = target_page.content()
        with open(HTML_FILE, "w", encoding="utf-8") as f:
            f.write(html_code)

        print(f"HTML –∫–æ–¥ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª {HTML_FILE}")
        browser.close()

def process_ge_pro_kml(input_path, output_path, folders_to_copy, regions_dict):
    parser = etree.XMLParser(remove_blank_text=True, recover=True)
    tree = etree.parse(input_path, parser)
    root = tree.getroot()

    #–ò–∑–º–µ–Ω–µ–Ω–∏–µ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    doc_name = root.find(f".//{{{KML_NS}}}Document/{{{KML_NS}}}name")
    doc_name.text = output_path.replace(".kml", '').strip()

    # –ü–æ–∏—Å–∫ Document ‚Äî –≥–ª–∞–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ Google Earth
    document = root.find("{{{}}}Document".format(KML_NS))
    if document is None:
        document = root

    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –ø–∞–ø–∫–∏ –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è
    folders = document.findall("{{{}}}Folder".format(KML_NS))

    for folder in folders:
        name_node = folder.find("{{{}}}name".format(KML_NS))
        folder_name = name_node.text if name_node is not None else "Unnamed Folder"

        if folder_name in folders_to_copy:
            print(f"üì¶ –ö–æ–ø–∏—Ä—É–µ–º –ø–∞–ø–∫—É –ø–æ–ª–Ω–æ—Å—Ç—å—é: {folder_name}")
            # –ù–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º, –æ–Ω–∞ –æ—Å—Ç–∞–µ—Ç—Å—è –≤ –¥–µ—Ä–µ–≤–µ —Å–æ –≤—Å–µ–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º
        else:
            print(f"üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –ø–∞–ø–∫–∏: {folder_name}")
            # –ü–†–ò–ú–ï–† –û–ë–†–ê–ë–û–¢–ö–ò: –£–¥–∞–ª—è–µ–º –≤—Å—ë, –∫—Ä–æ–º–µ Placemark —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º —Å—Ç–∏–ª–µ–º
            # –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —É–¥–∞–ª—è–µ–º –ø–∞–ø–∫—É, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ –Ω—É–∂–Ω–∞

            # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å –ø–∞–ø–∫—É —Ü–µ–ª–∏–∫–æ–º:
            # document.remove(folder)

            # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –º–µ—Ç–∫–∏ –≤–Ω—É—Ç—Ä–∏ —ç—Ç–æ–π –ø–∞–ø–∫–∏:
            placemarks = folder.findall("{{{}}}Placemark".format(KML_NS))
            print(f"–ù–∞–π–¥–µ–Ω–æ Placemark'–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(placemarks)} –≤ —Ñ–∞–π–ª–µ {folder_name}")

            found_in_kml = set()

            for pm in placemarks:
                # **–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å lxml –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–º–µ–Ω–∏ –≤ —Ä–∞–º–∫–∞—Ö KML_NS**
                name_node = pm.find('{{{}}}name'.format(KML_NS))

                if name_node is not None and name_node.text:
                    kml_name = name_node.text.strip()
                    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω–∏ KML –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å–æ —Å–ª–æ–≤–∞—Ä–µ–º: LP-D10 -> d10
                    ban_words = ['lp-', 'lp', 'area', 'fall', 'land']
                    pm_name_normalized = kml_name.lower()
                    for ban in ban_words:
                        pm_name_normalized = pm_name_normalized.replace(ban, '')
                    pm_name_normalized = pm_name_normalized.strip().split()[0]

                    if pm_name_normalized in regions_dict:

                        if pm_name_normalized not in found_in_kml:
                            found_in_kml.add(pm_name_normalized)

                        # 1. –û–±–Ω–æ–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ (–∏—Å–ø–æ–ª—å–∑—É—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å)
                        data_list = regions_dict[pm_name_normalized]
                        description_html = "\n".join(data_list)

                        desc_node = pm.find('{{{}}}description'.format(KML_NS))
                        if desc_node is None:
                            # –ï—Å–ª–∏ description –Ω–µ—Ç, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º NS
                            desc_node = etree.SubElement(pm, '{{{}}}description'.format(KML_NS))
                        else:
                            description_html = description_html + '\n \n' + str(desc_node.text)
                        desc_node.text = etree.CDATA(description_html)

                        # 2. –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω–ª–∞–π–Ω–æ–≤—ã–π –∫—Ä–∞—Å–Ω—ã–π —Å—Ç–∏–ª—å
                        # old_style_url = pm.find('{{{}}}styleUrl'.format(KML_NS))
                        # if old_style_url is not None:
                        #     pm.remove(old_style_url)

                        # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ç–∞–∫–∂–µ —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞ NS
                        # colors = {'red': "ff2a00", 'blue': '0015ff', 'orange': 'FF8C00', 'black': '000000'}
                        # style = etree.SubElement(pm, '{{{}}}Style'.format(KML_NS))
                        # poly_style = etree.SubElement(style, '{{{}}}PolyStyle'.format(KML_NS))
                        # color = etree.SubElement(poly_style, '{{{}}}color'.format(KML_NS))
                        # color.text = "7f0000ff"
                        # outline = etree.SubElement(poly_style, '{{{}}}outline'.format(KML_NS))
                        # outline.text = "1"
                        # line_style = etree.SubElement(style, '{{{}}}LineStyle'.format(KML_NS))
                        # l_color = etree.SubElement(line_style, '{{{}}}color'.format(KML_NS))
                        # l_color.text = "ff0000ff"
                        # l_width = etree.SubElement(line_style, '{{{}}}width'.format(KML_NS))
                        # l_width.text = "2"
                    else:
                        folder.remove(pm)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º –æ–±—ä—è–≤–ª–µ–Ω–∏–µ–º XML –¥–ª—è Google Earth
    with open(output_path, 'wb') as f:
        f.write(etree.tostring(tree,
                               pretty_print=True,
                               xml_declaration=True,
                               encoding='utf-8'))

def parse_eaup_htm(file_path):
    # (–í–∞—à–∞ —Ñ—É–Ω–∫—Ü–∏—è parse_eaup_html –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    if not os.path.exists(file_path): return {}
    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
        soup = BeautifulSoup(f, 'html.parser')
    rows = soup.find_all('tr')
    seen_records = set()
    parsed_lp_regions = dict()
    for row in rows:
        cells = row.find_all(['td', 'th'])
        row_text = "|".join([c.get_text(strip=True) for c in cells if c.get_text(strip=True)])
        name_match = re.search(r'\b(LP\w+)\b', row_text)
        if name_match:
            region_name = name_match.group(1)
            if region_name == "LPA": continue
            times = re.findall(r'\d{2}:\d{2}', row_text)
            if len(times) > 4 or len(times) < 2: continue
            time_str = " - ".join(times[:2])
            raw_levels = re.findall(r'\b(\d{3})\b|SFC', row_text)
            altitudes = []
            for lvl in raw_levels:
                val = lvl if isinstance(lvl, tuple) and lvl else (lvl if isinstance(lvl, tuple) else lvl)
                if not val: continue
                if val.upper() == 'SFC' or val.isdigit() and int(val) == 0:
                    val = 'GND'
                elif val.isdigit() and int(val) < 245:
                    val = f"{int(val) * 100} ft"
                elif val.isdigit() and int(val) >= 245:
                    val = 'FL245'
                altitudes.append(val)
            clean_alts = altitudes[:2]
            alt_display = '/'.join(clean_alts) if clean_alts else "–Ω–µ —É–∫–∞–∑–∞–Ω—ã"
            record_key = f"{region_name}|{time_str}|{alt_display}"
            if record_key not in seen_records:
                seen_records.add(record_key)
                clean_region_name = region_name[2:].lower().replace('-', '').strip()
                time_alt_string = f"{time_str} | {alt_display} AMSL"
                print(clean_region_name, time_alt_string)
                if clean_region_name in parsed_lp_regions:
                    parsed_lp_regions[clean_region_name].append(time_alt_string)
                else:
                    parsed_lp_regions[clean_region_name] = [time_alt_string]
    return parsed_lp_regions


if __name__ == "__main__":
    download_page()
    print(f"–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ {HTML_FILE}...")
    try:
        lp_regions = parse_eaup_htm(HTML_FILE)
    except FileNotFoundError:
        print(f"–§–∞–π–ª {HTML_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        exit(1)

    if lp_regions:
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(lp_regions)} –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤ –≤ HTML-–¥–∞–Ω–Ω—ã—Ö.")
        process_ge_pro_kml(INPUT_KML, OUTPUT_KML, FULL_COPY, lp_regions)
        print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {OUTPUT_KML}.")
    else:
        print("–†–µ–≥–∏–æ–Ω—ã –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, KML –Ω–µ —Å–æ–∑–¥–∞–Ω.")

